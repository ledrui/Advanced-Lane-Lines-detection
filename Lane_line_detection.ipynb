{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding\n",
    "## Udacity Self-Driving Car Nanodegree\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "The goal of this project is to write a software pipeline to indentify the lane\n",
    "boundaries in a video with a front-facing camera on a car.  The camera<br>\n",
    "calibration images, test road images, and project videos are available<br>\n",
    "in this project repository:  https://github.com/udacity/CarND-Advanced-Lane-Lines\n",
    "\n",
    "<br>\n",
    "Below is a summary of the techniques used in this project.\n",
    "\n",
    "1. Camera calibration\n",
    "2. Distortion correction\n",
    "3. Color/gradient threshold\n",
    "4. Perspective transform\n",
    "5. Detect lane lines\n",
    "6. Determine the lane curvature\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.measurements import label\n",
    "from collections import deque\n",
    "from featureExtraction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Lane Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera Calibration\n",
    "import os\n",
    "import cameraCalibration\n",
    "(ret, cameraMat, distCoeffs, rvecs, tvecs), fig = cameraCalibration.get_calibration_matrix(os.path.join('camera_cal','*.jpg'))\n",
    "plt.close()\n",
    "\n",
    "# Perspective Transform Params\n",
    "img_size = (1280, 720)\n",
    "width, height = img_size\n",
    "offset = 200\n",
    "src = np.float32([\n",
    "    [  588,   446 ],\n",
    "    [  691,   446 ],\n",
    "    [ 1126,   673 ],\n",
    "    [  153 ,   673 ]])\n",
    "dst = np.float32([[offset, 0], [img_size[0] - offset, 0], [img_size[0] - offset, img_size[1]], [offset, img_size[1]]])\n",
    "M = cv2.getPerspectiveTransform(src,dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "# Lane Detection Pipeline\n",
    "from lane_pipeline import LanePipeline\n",
    "from line import Line\n",
    "line=Line()\n",
    "LanePipeline.set_values(line, M, Minv, cameraMat, distCoeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    lane_detected = LanePipeline.pipeline(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the pipeline to the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "white_output = 'project_lane_video_output.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")#.subclip(t_start=30,t_end=35)\n",
    "white_clip = clip.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
